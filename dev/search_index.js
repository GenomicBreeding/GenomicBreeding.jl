var documenterSearchIndex = {"docs":
[{"location":"references/#Methods-reference","page":"Reference","title":"Methods reference","text":"","category":"section"},{"location":"references/","page":"Reference","title":"Reference","text":"Pages = [\"references.md\"]","category":"page"},{"location":"references/","page":"Reference","title":"Reference","text":"Modules = [GenomicBreeding]","category":"page"},{"location":"references/#GenomicBreeding.GBInput","page":"Reference","title":"GenomicBreeding.GBInput","text":"mutable struct GBInput\n\nMain input struct for genomic breeding analysis (implements GBCore.AbstractGB)\n\nFields\n\nRequired\n\nfname_geno: Path to genotype file (see file format guide for details)\n\nOptional Data Files\n\nfname_pheno: Path to phenotype file (Default: \"\" - see file format guide for details)\nfname_allele_effects_jld2s: Vector of paths to JLD2 files containing Fit structs (Default: [\"\"])\n\nAnalysis Settings\n\nanalysis: Analysis function to perform (Default: cv)\ncv: Replicated k-fold cross-validation\nfit: Fit genomic prediction models to extract allele effects\npredict: Compute GEBVs using existing model fits\ngwas: Genome-wide association study\nbulk_cv: Perform cross-validation across all populations (Default: false)\npopulations: Vector of populations to include (Default: all)\ntraits: Vector of traits to analyze (Default: all)\nmodels: Vector of genomic prediction model functions (Default: [ridge, bayesa])\ngwas_models: Vector of GWAS model functions (Default: [gwasols, gwaslmm])\n\nCross-Validation Parameters\n\nn_folds: Number of CV folds (Default: 5)\nn_replications: Number of CV replications (Default: 5)\n\nFiltering Parameters\n\nkeep_all: Keep all entries when merging data (Default: false)\nmaf: Minimum allele frequency (Default: 0.05)\nmtv: Minimum trait variance (Default: 1e-7)\n\nModel Parameters\n\nn_iter: MCMC iterations (Default: 1_500)\nn_burnin: MCMC burn-in iterations (Default: 500)\n\nOutput Settings\n\nfname_out_prefix: Output file prefix & directory (Default: GBOutput/output-<timestamp>-)\nverbose: Show progress messages (Default: true)\n\nSLURM Settings\n\nSLURM_job_name: Job array name (Default: GBJob-<timestamp>)\nSLURM_account_name: Account name (Default: \"\")\nSLURM_partition_name: Partition to use (Default: \"\")\nSLURM_nodes_per_array_job: Nodes per job (Default: 1)\nSLURM_tasks_per_node: Tasks per node (Default: 1)\nSLURM_cpus_per_task: CPUs per task (Default: 1)\nSLURM_mem_G: Memory in GB (Default: 1)\nSLURM_time_limit_dd_hhmmss: Time limit as \"dd-hh:mm:ss\" (Default: \"00-01:00:00\")\nSLURM_max_array_jobs_running: Max concurrent array jobs (Default: 20)\nSLURM_module_load_Conda_version_name: Conda module name (Default: \"Miniconda3\")\nSLURM_module_load_R_version_name: R module name (Default: \"conda\" which will use the R installed in the conda environment - see installation instructions for details)\nSLURM_module_load_Julia_version_name: Julia module name (Default: \"\" which will use the Julia installed via JuliaUp - see installation instructions for details)\n\n\n\n\n\n","category":"type"},{"location":"references/#Base.:==-Tuple{GBInput, GBInput}","page":"Reference","title":"Base.:==","text":"Base.:(==)(x::GBInput, y::GBInput)::Bool\n\nCompare two GBInput structs for equality by comparing their hash values.\n\nThis method overloads the == operator for GBInput structs, allowing direct comparison using the == operator. Two GBInput structs are considered equal if they have identical hash values, which implies they have the same values for all relevant fields.\n\nArguments\n\nx::GBInput: First GBInput struct to compare\ny::GBInput: Second GBInput struct to compare\n\nReturns\n\nBool: true if the hash values of both structs are equal, false otherwise\n\nExamples\n\njulia> input_1 = input = GBInput(fname_geno=\"geno1.jld2\", fname_pheno=\"pheno1.jld2\", fname_out_prefix=\"test1-\", SLURM_job_name=\"slurmjob1\");\n\njulia> input_2 = input = GBInput(fname_geno=\"geno1.jld2\", fname_pheno=\"pheno1.jld2\", fname_out_prefix=\"test1-\", SLURM_job_name=\"slurmjob1\");\n\njulia> input_3 = input = GBInput(fname_geno=\"geno2.jld2\", fname_pheno=\"pheno2.jld2\");\n\njulia> input_1 == input_2\ntrue\n\njulia> input_1 == input_3\nfalse\n\n\n\n\n\n","category":"method"},{"location":"references/#Base.hash-Tuple{GBInput, UInt64}","page":"Reference","title":"Base.hash","text":"Base.hash(x::GBInput, h::UInt)::UInt\n\nCompute a hash value for a GBInput struct by combining the hash values of all its fields.\n\nArguments\n\nx::GBInput: The input structure to be hashed\nh::UInt: The hash value seed\n\nReturns\n\nUInt: A hash value that uniquely identifies the content of the GBInput struct\n\nDetails\n\nThis method implements hash computation for the GBInput type by iterating through all fields and combining their hash values.\n\nExamples\n\njulia> input = GBInput(fname_geno=\"\", fname_pheno=\"\");\n\njulia> typeof(hash(input))\nUInt64\n\n\n\n\n\n","category":"method"},{"location":"references/#GBCore.checkdims-Tuple{GBInput}","page":"Reference","title":"GBCore.checkdims","text":"checkdims(input::GBInput)::Bool\n\nCheck dimension compatibility of the fields of the GBInput struct. Returns true if both models and gwas_models fields in the input are not nothing, false otherwise.\n\nArguments\n\ninput::GBInput: Input structure containing genomic data and models\n\nReturns\n\nBool: true if dimensions are compatible, false otherwise\n\nExamples\n\njulia> input = GBInput(fname_geno=\"geno1.jld2\", fname_pheno=\"pheno1.jld2\");\n\njulia> checkdims(input)\ntrue\n\njulia> input.models = nothing\n\njulia> checkdims(input)\nfalse\n\n\n\n\n\n","category":"method"},{"location":"references/#GBCore.clone-Tuple{GBInput}","page":"Reference","title":"GBCore.clone","text":"clone(x::GBInput)::GBInput\n\nCreate a deep copy of a GBInput object, duplicating all field values into a new instance.\n\nThis function allows you to create an independent copy of a GBInput object where modifications  to the clone won't affect the original object.\n\nArguments\n\nx::GBInput: The source GBInput object to be cloned\n\nReturns\n\n::GBInput: A new GBInput instance with identical field values\n\nExample\n\njulia> input = GBInput(fname_geno=\"geno1.jld2\", fname_pheno=\"pheno1.jld2\");\n\njulia> copy_input = clone(input);\n\njulia> input == copy_input\ntrue\n\n\n\n\n\n","category":"method"},{"location":"references/#GenomicBreeding.checkinputs-Tuple{GBInput}","page":"Reference","title":"GenomicBreeding.checkinputs","text":"checkinputs(input::GBInput)::Vector{String}\n\nCheck the compatibility and validity of inputs for genomic analysis.\n\nReturns a vector of error messages. An empty vector indicates all inputs are valid.\n\nArguments\n\ninput::GBInput: A struct containing analysis parameters including:\nanalysis: Analysis type (cv, fit, predict, or gwas)\nfname_geno: Path to genotype file\nfname_pheno: Path to phenotype file\nmodels: Vector of selected models\nfname_allele_effects_jld2s: Paths to allele effects files (for predict)\n\nReturns\n\nVector{String}: Collection of error messages, empty if all inputs are valid\n\nValidation Rules\n\nAnalysis type must be one of: cv, fit, predict, or gwas\nFor cv, fit, and gwas:\nGenotype file must exist\nPhenotype file must exist\nAt least one model must be specified\nFor predict:\nGenotype file must exist\nAll specified allele effects files must exist\n\nExamples\n\njulia> genomes = GBCore.simulategenomes(n=300, verbose=false); genomes.populations = StatsBase.sample(string.(\"pop_\", 1:3), length(genomes.entries), replace=true);\n\njulia> trials, _ = GBCore.simulatetrials(genomes=genomes, n_years=1, n_seasons=1, n_harvests=1, n_sites=1, n_replications=1, verbose=false);\n\njulia> phenomes = extractphenomes(trials);\n\njulia> fname_geno = try writedelimited(genomes, fname=\"test-geno.tsv\"); catch; rm(\"test-geno.tsv\"); writedelimited(genomes, fname=\"test-geno.tsv\"); end;\n    \njulia> fname_pheno = try writedelimited(phenomes, fname=\"test-pheno.tsv\"); catch; rm(\"test-pheno.tsv\"); writedelimited(phenomes, fname=\"test-pheno.tsv\"); end;\n\njulia> input = GBInput(fname_geno=fname_geno, fname_pheno=fname_pheno, analysis=cv);\n\njulia> length(checkinputs(input)) == 0\ntrue\n\njulia> input.fname_pheno = \"\"; length(checkinputs(input)) == 0\nfalse\n\n\n\n\n\n","category":"method"},{"location":"references/#GenomicBreeding.cv-Tuple{GBInput}","page":"Reference","title":"GenomicBreeding.cv","text":"cv(input::GBInput)::Tuple{Vector{String},Vector{String}}\n\nAssess genomic prediction accuracy via replicated k-fold cross-validation.\n\nArguments\n\ninput::GBInput: A GBInput struct containing configuration parameters including:\nbulk_cv: Boolean flag for bulk cross-validation\npopulations: Vector of population names to analyze\nmodels: Statistical models to use for prediction\nn_folds: Number of folds for cross-validation\nn_replications: Number of replications for cross-validation\nfname_out_prefix: Prefix for output filenames\nverbose: Boolean flag for detailed output\n\nReturns\n\nTuple{Vector{String},Vector{String}}: A tuple containing:\nFirst element: Vector of paths to JLD2 files containing CV results\nSecond element: Vector of paths to text files containing error notes\n\nDetails\n\nThe function supports three types of cross-validation:\n\nSingle population CV when one population is specified\nPairwise population CV when two populations are specified\nBoth pairwise and leave-one-population-out CV when more than two populations are specified\n\nResults are saved as JLD2 files (one per fold, replication, and trait) and optional text files  containing notes about failed jobs.\n\nExample\n\njulia> genomes = GBCore.simulategenomes(n=300, l=1_000, verbose=false); genomes.populations = StatsBase.sample(string.(\"pop_\", 1:3), length(genomes.entries), replace=true);\n\njulia> proportion_of_variance = fill(0.0, 9, 3); proportion_of_variance[1, :] .= 1.00; # 100% variance on the additive genetic effects\n\njulia> trials, _ = GBCore.simulatetrials(genomes=genomes, n_years=1, n_seasons=1, n_harvests=1, n_sites=1, n_replications=1, proportion_of_variance=proportion_of_variance, verbose=false);\n\njulia> phenomes = extractphenomes(trials);\n\njulia> fname_geno = try writedelimited(genomes, fname=\"test-geno.tsv\"); catch; rm(\"test-geno.tsv\"); writedelimited(genomes, fname=\"test-geno.tsv\"); end;\n\njulia> fname_pheno = try writedelimited(phenomes, fname=\"test-pheno.tsv\"); catch; rm(\"test-pheno.tsv\"); writedelimited(phenomes, fname=\"test-pheno.tsv\"); end;\n\njulia> input = GBInput(fname_geno=fname_geno, fname_pheno=fname_pheno, analysis=cv, bulk_cv=false, fname_out_prefix=\"GBOutput_cv_3/output-3-\", populations=[\"pop_1\", \"pop_3\"], traits=[\"trait_1\"], n_replications=2, n_folds=3, verbose=false);\n\njulia> fnames_cvs, fnames_notes = cv(input);\n\njulia> length(fnames_cvs) == 4, length(fnames_notes) == 0\n(true, true)\n\n\n\n\n\n","category":"method"},{"location":"references/#GenomicBreeding.fit-Tuple{GBInput}","page":"Reference","title":"GenomicBreeding.fit","text":"fit(input::GBInput)::Vector{String}\n\nExtract allele effects by fitting genomic prediction models without cross-validation.\n\nArguments\n\ninput::GBInput: A GBInput struct containing:\nfname_geno: Path to genotype data file\nfname_pheno: Path to phenotype data file\nmodels: Vector of model functions to fit (e.g., [bayesa, bayesb])\ntraits: Optional vector of trait names to analyze\npopulations: Optional vector of population names to analyze\nn_iter: Number of iterations for Bayesian models\nn_burnin: Number of burn-in iterations for Bayesian models\nverbose: Boolean for detailed output\n\nReturns\n\nVector{String}: Paths to JLD2 files containing fitted model results, one file per model-trait-population combination\n\nDetails\n\nThe function fits specified genomic prediction models to the full dataset without cross-validation.  For each combination of model, trait, and population, it:\n\nLoads and processes genotype and phenotype data\nFits the specified model\nSaves results to a JLD2 file with naming pattern: {prefix}_model_{name}-trait_{name}-population_{name}.jld2\n\nNotes\n\nIf populations is not specified, all unique populations in phenotype data are used\nIf traits is not specified, all unique traits in phenotype data are used\nFor Bayesian models (names containing \"bayes\"), uses specified iterations and burn-in\nWill throw an error if output files already exist\n\nExample\n\njulia> genomes = GBCore.simulategenomes(n=300, l=1_000, verbose=false); genomes.populations = StatsBase.sample(string.(\"pop_\", 1:3), length(genomes.entries), replace=true);\n\njulia> proportion_of_variance = fill(0.0, 9, 3); proportion_of_variance[1, :] .= 1.00; # 100% variance on the additive genetic effects\n\njulia> trials, _ = GBCore.simulatetrials(genomes=genomes, n_years=1, n_seasons=1, n_harvests=1, n_sites=1, n_replications=1, proportion_of_variance=proportion_of_variance, verbose=false);\n\njulia> phenomes = extractphenomes(trials);\n\njulia> fname_geno = try writedelimited(genomes, fname=\"test-geno.tsv\"); catch; rm(\"test-geno.tsv\"); writedelimited(genomes, fname=\"test-geno.tsv\"); end;\n\njulia> fname_pheno = try writedelimited(phenomes, fname=\"test-pheno.tsv\"); catch; rm(\"test-pheno.tsv\"); writedelimited(phenomes, fname=\"test-pheno.tsv\"); end;\n\njulia> input = GBInput(fname_geno=fname_geno, fname_pheno=fname_pheno, analysis=GenomicBreeding.fit, fname_out_prefix=\"GBOutput_fit_4/output-4-\", populations=[\"pop_1\", \"pop_3\"], traits=[\"trait_1\"], models=[bayesa, bayesb], verbose=false);\n\njulia> fname_allele_effects_jld2s = GenomicBreeding.fit(input);\n\njulia> length(fname_allele_effects_jld2s) == 4\ntrue\n\n\n\n\n\n","category":"method"},{"location":"references/#GenomicBreeding.gwas-Tuple{GBInput}","page":"Reference","title":"GenomicBreeding.gwas","text":"gwas(input::GBInput)::Vector{String}\n\nPerform genome-wide association study (GWAS) analysis on genomic and phenotypic data.\n\nArguments\n\ninput::GBInput: A GBInput struct containing:\nfname_geno: Path to genotype data file\nfname_pheno: Path to phenotype data file\ngwas_models: Vector of GWAS models to apply\ntraits: Optional vector of trait names to analyze\npopulations: Optional vector of population names to analyze\nverbose: Boolean flag for detailed output\n\nReturns\n\nVector{String}: Paths to generated JLD2 files containing Fit structs for each model-trait-population combination\n\nDetails\n\nThe function performs GWAS analysis for each combination of:\n\nGWAS models specified in input\nTraits found in phenotype data\nPopulations specified (if none specified, analyzes all data together)\n\nFor each combination, it:\n\nFilters data for the specific population if specified\nFits the GWAS model\nSaves results to a JLD2 file containing a Fit struct\n\nThe Fit struct's b_hat field contains:\n\nt-statistics for gwasols model\nz-statistics for other GWAS models\n\nNotes\n\nOutput files are named as: <prefix>_model_<model>-trait_<trait>-population_<pop>.jld2\nWill throw an error if output files already exist\nWhen verbose=true, displays a progress bar and correlation heatmap of estimated allele effects\n\nExample\n\njulia> genomes = GBCore.simulategenomes(n=300, l=1_000, verbose=false); genomes.populations = StatsBase.sample(string.(\"pop_\", 1:3), length(genomes.entries), replace=true);\n\njulia> proportion_of_variance = fill(0.0, 9, 3); proportion_of_variance[1, :] .= 1.00; # 100% variance on the additive genetic effects\n\njulia> trials, _ = GBCore.simulatetrials(genomes=genomes, n_years=1, n_seasons=1, n_harvests=1, n_sites=1, n_replications=1, proportion_of_variance=proportion_of_variance, verbose=false);\n\njulia> phenomes = extractphenomes(trials);\n\njulia> fname_geno = try writedelimited(genomes, fname=\"test-geno.tsv\"); catch; rm(\"test-geno.tsv\"); writedelimited(genomes, fname=\"test-geno.tsv\"); end;\n\njulia> fname_pheno = try writedelimited(phenomes, fname=\"test-pheno.tsv\"); catch; rm(\"test-pheno.tsv\"); writedelimited(phenomes, fname=\"test-pheno.tsv\"); end;\n\njulia> input = GBInput(fname_geno=fname_geno, fname_pheno=fname_pheno, gwas_models=[gwasols], verbose=false);\n\njulia> fname_test_statistics_jld2s = GenomicBreeding.gwas(input);\n\njulia> length(fname_test_statistics_jld2s) == 3\ntrue\n\n\n\n\n\n","category":"method"},{"location":"references/#GenomicBreeding.loadcvs-Tuple{GBInput}","page":"Reference","title":"GenomicBreeding.loadcvs","text":"loadcvs(input::GBInput; min_train_size::Int64=10)::Vector{CV}\n\nLoad and filter cross-validation (CV) results from files generated by GenomicBreeding.cv().\n\nArguments\n\ninput::GBInput: Input configuration containing the output directory path in fname_out_prefix\nmin_train_size::Int64=10: Minimum required size for training sets (default: 10)\n\nReturns\n\nVector{CV}: Vector of valid CV objects that meet the following criteria:\nContains complete metrics (length of fit.metrics == 9)\nHas valid correlation metric (not missing, NaN, or Inf)\nValidation set size ≥ mintrainsize\n\nThrows\n\nArgumentError: If the output directory doesn't exist or contains no CV results\n\nDetails\n\nThe function searches for files with pattern \"-cv-\" and extension \".jld2\" in the output directory. Invalid or failed CV results are automatically filtered out during loading.\n\nExample\n\njulia> genomes = GBCore.simulategenomes(n=300, l=1_000, verbose=false); genomes.populations = StatsBase.sample(string.(\"pop_\", 1:3), length(genomes.entries), replace=true);\n\njulia> proportion_of_variance = fill(0.0, 9, 3); proportion_of_variance[1, :] .= 1.00; # 100% variance on the additive genetic effects\n\njulia> trials, _ = GBCore.simulatetrials(genomes=genomes, n_years=1, n_seasons=1, n_harvests=1, n_sites=1, n_replications=1, proportion_of_variance=proportion_of_variance, verbose=false);\n\njulia> phenomes = extractphenomes(trials);\n\njulia> fname_geno = try writedelimited(genomes, fname=\"test-geno.tsv\"); catch; rm(\"test-geno.tsv\"); writedelimited(genomes, fname=\"test-geno.tsv\"); end;\n\njulia> fname_pheno = try writedelimited(phenomes, fname=\"test-pheno.tsv\"); catch; rm(\"test-pheno.tsv\"); writedelimited(phenomes, fname=\"test-pheno.tsv\"); end;\n\njulia> input = GBInput(fname_geno=fname_geno, fname_pheno=fname_pheno, fname_out_prefix=\"GBOutput_cv_1/output-1-\", populations=[\"pop_1\", \"pop_3\"], traits=[\"trait_1\"], n_replications=2, n_folds=3, verbose=false);\n\njulia> fnames_cvs, fnames_notes = cv(input);\n\njulia> cvs = loadcvs(input);\n\njulia> length(cvs) == length(fnames_cvs)\ntrue\n\n\n\n\n\n","category":"method"},{"location":"references/#GenomicBreeding.loadfits-Tuple{GBInput}","page":"Reference","title":"GenomicBreeding.loadfits","text":"loadfits(input::GBInput)::Vector{Fit}\n\nLoad fitted allele frequency effects from genomic prediction models stored in JLD2 files.\n\nArguments\n\ninput::GBInput: Input configuration containing paths to JLD2 files with fitted allele effects.\n\nReturns\n\nVector{Fit}: Array of Fit objects containing the loaded allele frequency effects.\n\nDetails\n\nThe function attempts to load all JLD2 files specified in input.fname_allele_effects_jld2s. If a file cannot be loaded, that entry will be skipped and remain undef in the output vector.\n\nExample\n\njulia> genomes = GBCore.simulategenomes(n=300, l=1_000, verbose=false); genomes.populations = StatsBase.sample(string.(\"pop_\", 1:3), length(genomes.entries), replace=true);\n\njulia> proportion_of_variance = fill(0.0, 9, 3); proportion_of_variance[1, :] .= 1.00; # 100% variance on the additive genetic effects\n\njulia> trials, _ = GBCore.simulatetrials(genomes=genomes, n_years=1, n_seasons=1, n_harvests=1, n_sites=1, n_replications=1, proportion_of_variance=proportion_of_variance, verbose=false);\n\njulia> phenomes = extractphenomes(trials);\n\njulia> fname_geno = try writedelimited(genomes, fname=\"test-geno.tsv\"); catch; rm(\"test-geno.tsv\"); writedelimited(genomes, fname=\"test-geno.tsv\"); end;\n\njulia> fname_pheno = try writedelimited(phenomes, fname=\"test-pheno.tsv\"); catch; rm(\"test-pheno.tsv\"); writedelimited(phenomes, fname=\"test-pheno.tsv\"); end;\n\njulia> input = GBInput(fname_geno=fname_geno, fname_pheno=fname_pheno, fname_out_prefix=\"GBOutput_fit_2/output-2-\", populations=[\"pop_1\", \"pop_3\"], traits=[\"trait_1\"], models=[bayesa, bayesb], verbose=false);\n\njulia> input.fname_allele_effects_jld2s = GenomicBreeding.fit(input);\n\njulia> fits = loadfits(input);\n\njulia> length(fits) == length(input.fname_allele_effects_jld2s)\ntrue\n\n\n\n\n\n","category":"method"},{"location":"references/#GenomicBreeding.loadgenomesphenomes-Tuple{GBInput}","page":"Reference","title":"GenomicBreeding.loadgenomesphenomes","text":"loadgenomesphenomes(input::GBInput)::Tuple{Genomes, Phenomes, Vector{String}, Vector{String}}\n\nLoad, merge, and filter genotype and phenotype data from specified input files.\n\nArguments\n\ninput::GBInput: A struct containing input parameters including:\nfname_geno: Path to genotype data file\nfname_pheno: Path to phenotype data file\nbulk_cv: Boolean for bulk cross-validation\npopulations: Vector of population names to include (optional)\ntraits: Vector of trait names to include (optional)\nn_folds: Number of cross-validation folds\nkeep_all: Boolean to keep all entries during merging\nmaf: Minimum allele frequency threshold\nmtv: Minimum trait variance threshold\nverbose: Boolean for detailed output\n\nReturns\n\nA tuple containing:\n\nGenomes: Filtered genomic data\nPhenomes: Filtered phenotypic data\nVector{String}: Traits to skip due to insufficient data for cross-validation\nVector{String}: Populations to skip due to insufficient data for cross-validation\n\nNotes\n\nSupports multiple file formats (string-delimited, JLD2, VCF)\nPerforms data validation and compatibility checks\nFilters traits with variance below minimum trait variance (mtv) threshold\nEnsures sufficient sample size for cross-validation\nFilters markers based on minimum allele frequency (maf)\n\nExamples\n\njulia> genomes = GBCore.simulategenomes(n=300, verbose=false); genomes.populations = StatsBase.sample(string.(\"pop_\", 1:3), length(genomes.entries), replace=true);\n\njulia> trials, _ = GBCore.simulatetrials(genomes=genomes, n_years=1, n_seasons=1, n_harvests=1, n_sites=1, n_replications=1, verbose=false);\n\njulia> phenomes = extractphenomes(trials);\n\njulia> fname_geno = try writedelimited(genomes, fname=\"test-geno.tsv\"); catch; rm(\"test-geno.tsv\"); writedelimited(genomes, fname=\"test-geno.tsv\"); end;\n    \njulia> fname_pheno = try writedelimited(phenomes, fname=\"test-pheno.tsv\"); catch; rm(\"test-pheno.tsv\"); writedelimited(phenomes, fname=\"test-pheno.tsv\"); end;\n\njulia> input = GBInput(fname_geno=fname_geno, fname_pheno=fname_pheno, populations=[\"pop_1\", \"pop_3\"], traits=[\"trait_1\"], verbose=false);\n\njulia> genomes, phenomes, traits_to_skip, populations_to_skip = loadgenomesphenomes(input);\n\njulia> length(unique(genomes.populations)) == length(unique(phenomes.populations)) == 2\ntrue\n\njulia> length(phenomes.traits) == 1\ntrue\n\njulia> rm.([fname_geno, fname_pheno]);\n\n\n\n\n\n","category":"method"},{"location":"references/#GenomicBreeding.plot-Tuple{}","page":"Reference","title":"GenomicBreeding.plot","text":"plot(;\n    input::GBInput,\n    skip_genomes::Bool = false,\n    skip_phenomes::Bool = false,\n    skip_cvs::Bool = false,\n    format::String = \"svg\",\n    plot_size::Tuple{Int64,Int64} = (600, 450),\n    overwrite::Bool = false\n)::String\n\nGenerate and save visualization plots for genomic, phenomic, and cross-validation data.\n\nArguments\n\ninput::GBInput: Input configuration containing file paths and settings\nskip_genomes::Bool: If true, skip generating genome-related plots\nskip_phenomes::Bool: If true, skip generating phenome-related plots\nskip_cvs::Bool: If true, skip generating cross-validation plots\nformat::String: Output file format for plots (e.g., \"svg\", \"png\")\nplot_size::Tuple{Int64,Int64}: Dimensions of output plots in pixels (width, height)\noverwrite::Bool: If true, overwrite existing plot files\n\nReturns\n\nString: Path to the output directory containing generated plots\n\nPlot Types\n\nGenomes and Phenomes\n\nDistribution plots\nViolin plots\nCorrelation heatmaps\nTree plots\nPCA biplots\n\nCross-validation\n\nBar plots\nBox plots\n\nOutput Structure\n\nCreates a directory structure under input.fname_out_prefix/plots/ with subdirectories:\n\ngenomes/: Genome-related visualizations\nphenomes/: Phenome-related visualizations\ncvs/: Cross-validation visualizations\n\nExample\n\njulia> genomes = GBCore.simulategenomes(n=300, l=1_000, verbose=false); genomes.populations = StatsBase.sample(string.(\"pop_\", 1:3), length(genomes.entries), replace=true);\n\njulia> trials, _ = GBCore.simulatetrials(genomes=genomes, n_years=1, n_seasons=1, n_harvests=1, n_sites=1, n_replications=1, verbose=false);\n\njulia> phenomes = extractphenomes(trials);\n\njulia> fname_geno = try writedelimited(genomes, fname=\"test-geno.tsv\"); catch; rm(\"test-geno.tsv\"); writedelimited(genomes, fname=\"test-geno.tsv\"); end;\n\njulia> fname_pheno = try writedelimited(phenomes, fname=\"test-pheno.tsv\"); catch; rm(\"test-pheno.tsv\"); writedelimited(phenomes, fname=\"test-pheno.tsv\"); end;\n    \njulia> input = GBInput(fname_geno=fname_geno, fname_pheno=fname_pheno, SLURM_cpus_per_task=6, SLURM_mem_G=5, fname_out_prefix=\"GBOutput/test-\", verbose=false);\n\njulia> GenomicBreeding.plot(input=input, format=\"png\", plot_size = (700, 525))\n\"GBOutput/plots\"\n\njulia> GenomicBreeding.plot(input=input, format=\"png\", plot_size = (700, 525), overwrite=true, skip_genomes=true)\n\"GBOutput/plots\"\n\n\n\n\n\n","category":"method"},{"location":"references/#GenomicBreeding.predict-Tuple{GBInput}","page":"Reference","title":"GenomicBreeding.predict","text":"predict(input::GBInput)::String\n\nPredict trait values (GEBVs) for a set of genotypes using pre-trained models from GenomicBreeding.fit().\n\nArguments\n\ninput::GBInput: Input configuration containing:\nfname_geno: Path to genotype data file\nfname_allele_effects_jld2s: Vector of paths to saved model files from previous fit() calls\nfname_out_prefix: Prefix for output files\nanalysis: Set to GenomicBreeding.predict\n\nReturns\n\nString: Path to the JLD2 file containing predicted phenotypes\n\nDetails\n\nTakes a GBInput object with genotype data and pre-trained models to predict trait values  for new individuals. The function:\n\nLoads genotype data and model parameters\nPredicts trait values using the loaded models\nSaves predictions in a Phenomes struct\nReturns the path to the saved predictions file\n\nOutput File Format\n\nFor single trait prediction: {prefix}{model_name}-predicted_phenomes.jld2\nFor multi-trait prediction: {prefix}{hash}-predicted_phenomes.jld2\n\nExample\n\njulia> genomes = GBCore.simulategenomes(n=300, l=1_000, verbose=false); genomes.populations = StatsBase.sample(string.(\"pop_\", 1:3), length(genomes.entries), replace=true);\n\njulia> proportion_of_variance = fill(0.0, 9, 3); proportion_of_variance[1, :] .= 1.00; # 100% variance on the additive genetic effects\n\njulia> trials, _ = GBCore.simulatetrials(genomes=genomes, n_years=1, n_seasons=1, n_harvests=1, n_sites=1, n_replications=1, proportion_of_variance=proportion_of_variance, verbose=false);\n\njulia> phenomes = extractphenomes(trials);\n\njulia> fname_geno = try writedelimited(genomes, fname=\"test-geno.tsv\"); catch; rm(\"test-geno.tsv\"); writedelimited(genomes, fname=\"test-geno.tsv\"); end;\n\njulia> fname_pheno = try writedelimited(phenomes, fname=\"test-pheno.tsv\"); catch; rm(\"test-pheno.tsv\"); writedelimited(phenomes, fname=\"test-pheno.tsv\"); end;\n\njulia> input = GBInput(fname_geno=fname_geno, fname_pheno=fname_pheno, fname_out_prefix=\"GBOutput_predict_5/output-5-\", analysis=GenomicBreeding.fit, verbose=false);\n\njulia> input.fname_allele_effects_jld2s = GenomicBreeding.fit(input);\n\njulia> input.analysis = GenomicBreeding.predict;\n\njulia> fname_phenomes_predicted = GenomicBreeding.predict(input);\n\njulia> phenomes_predicted = readjld2(Phenomes, fname=fname_phenomes_predicted);\n\njulia> dimensions(phenomes_predicted)\nDict{String, Int64} with 8 entries:\n  \"n_total\"       => 5400\n  \"n_zeroes\"      => 0\n  \"n_nan\"         => 0\n  \"n_entries\"     => 300\n  \"n_traits\"      => 18\n  \"n_inf\"         => 0\n  \"n_populations\" => 3\n  \"n_missing\"     => 0\n\n\n\n\n\n","category":"method"},{"location":"references/#GenomicBreeding.prepareinputs-Tuple{GBInput}","page":"Reference","title":"GenomicBreeding.prepareinputs","text":"prepareinputs(input::GBInput)::Vector{GBInput}\n\nCreate a vector of GBInput objects for parallel processing based on the input configuration.\n\nArguments\n\ninput::GBInput: Initial input configuration containing analysis parameters.\n\nReturns\n\nVector{GBInput}: Array of GBInput objects configured for different combinations of:\nModels (RR-BLUP, BayesB, etc.)\nTraits from phenotype data\nPopulation groups (including bulk and across-population analyses)\n\nDetails\n\nFor different analysis types, the function generates the following combinations:\n\nCross-validation (cv): 2 models × traits × (populations + bulk + across-pop)\nModel fitting (fit): 2 models × traits × (populations + bulk)\nPrediction (predict): 1 GBInput per allele effects file\nGWAS (gwas): 1 model × traits × (populations + bulk)\n\nThe function handles special cases:\n\nSkips trait-population combinations with insufficient data\nAdjusts settings for bulk and across-population analyses\nConfigures specific parameters for prediction tasks\n\nExamples\n\njulia> genomes = GBCore.simulategenomes(n=300, l=1_000, verbose=false); genomes.populations = StatsBase.sample(string.(\"pop_\", 1:3), length(genomes.entries), replace=true);\n\njulia> trials, _ = GBCore.simulatetrials(genomes=genomes, n_years=1, n_seasons=1, n_harvests=1, n_sites=1, n_replications=1, verbose=false);\n\njulia> phenomes = extractphenomes(trials);\n\njulia> fname_geno = try writedelimited(genomes, fname=\"test-geno.tsv\"); catch; rm(\"test-geno.tsv\"); writedelimited(genomes, fname=\"test-geno.tsv\"); end;\n    \njulia> fname_pheno = try writedelimited(phenomes, fname=\"test-pheno.tsv\"); catch; rm(\"test-pheno.tsv\"); writedelimited(phenomes, fname=\"test-pheno.tsv\"); end;\n\njulia> input_cv = GBInput(fname_geno=fname_geno, fname_pheno=fname_pheno, analysis=GenomicBreeding.cv, verbose=false);\n\njulia> input_fit = GBInput(fname_geno=fname_geno, fname_pheno=fname_pheno, analysis=GenomicBreeding.fit, verbose=false);\n\njulia> input_predict = GBInput(fname_geno=fname_geno, fname_pheno=fname_pheno, fname_allele_effects_jld2s=[\"dummy.jld2\"], analysis=GenomicBreeding.predict, verbose=false); writejld2(Fit(n=1, l=1), fname=\"dummy.jld2\");\n\njulia> input_gwas = GBInput(fname_geno=fname_geno, fname_pheno=fname_pheno, analysis=GenomicBreeding.gwas, verbose=false);\n\njulia> inputs_cv = prepareinputs(input_cv); # expect 30 GBInputs = 2 models x 3 traits x (3 populations + 1 bulk + 1 across pops)\n\njulia> inputs_fit = prepareinputs(input_fit); # expect 24 GBInputs = 2 models x 3 traits x (3 populations + 1 bulk)\n\njulia> inputs_predict = prepareinputs(input_predict); # expect 1 GBInput = 1 dummy Fit struct\n\njulia> inputs_gwas = prepareinputs(input_gwas); # expect 24 GBInputs = 1 models x 3 traits x (3 populations + 1 bulk)\n\njulia> length(inputs_cv) == 30\ntrue\n\njulia> length(inputs_fit) == 24\ntrue\n\njulia> length(inputs_predict) == 1\ntrue\n\njulia> length(inputs_gwas) == 24\ntrue\n\njulia> rm.([fname_geno, fname_pheno, \"dummy.jld2\"]);\n\n\n\n\n\n","category":"method"},{"location":"references/#GenomicBreeding.prepareoutprefixandoutdir-Tuple{GBInput}","page":"Reference","title":"GenomicBreeding.prepareoutprefixandoutdir","text":"prepareoutprefixandoutdir(input::GBInput)::String\n\nPrepare the output directory and sanitize the output filename prefix for genomic breeding analysis results.\n\nThis function performs two main tasks:\n\nCreates the output directory if it doesn't exist\nSanitizes the output filename prefix by replacing problematic characters with underscores\n\nArguments\n\ninput::GBInput: Input configuration containing the output file prefix and analysis type\n\nReturns\n\nString: Sanitized output file prefix path\n\nDetails\n\nProblematic characters that are replaced include spaces, newlines, tabs, parentheses,  and special characters (&|:=+*%@!). The function also ensures the prefix ends with  the analysis type and a hyphen.\n\nThrows\n\nArgumentError: If unable to create the output directory\n\nExample\n\njulia> input = GBInput(fname_geno=\"some_dir/fname_geno.jld2\", fname_pheno=\"some_dir/fname_pheno.jld2\", fname_out_prefix=\"GBOutput/some@!_%&prefix\", verbose=false);\n\njulia> fname_out_prefix = prepareoutprefixandoutdir(input)\n\"GBOutput/some_____prefix-cv-\"\n\njulia> rm(dirname(fname_out_prefix), recursive=true);\n\n\n\n\n\n","category":"method"},{"location":"references/#GenomicBreeding.submitslurmarrayjobs-Tuple{GBInput}","page":"Reference","title":"GenomicBreeding.submitslurmarrayjobs","text":"submitslurmarrayjobs(; input::GBInput)::String\n\nSubmit an array of Slurm jobs for genomic prediction analysis.\n\nArguments\n\ninput::GBInput: A GBInput struct containing all necessary parameters for job submission and analysis.\n\nReturns\n\nString: Path to the output directory where results will be stored.\n\nDetails\n\nThis function handles the submission of parallel genomic prediction jobs to a Slurm cluster. It performs the following steps:\n\nValidates input parameters and checks for required R packages\nCreates necessary output directories\nPrepares individual job inputs\nGenerates Julia and Slurm scripts\nSubmits the array job to the Slurm scheduler\n\nThe function supports various genomic analyses including:\n\nCross-validation (cv)\nModel fitting (fit)\nPrediction (predict)\nGWAS analysis (gwas)\n\nJob Configuration\n\nUses Slurm array jobs for parallel execution\nConfigurable CPU, memory, and time limit parameters\nSupports both module-based and conda environments\nInteractive confirmation before job submission\n\nNotes\n\nRequires a working Slurm environment\nBGLR R package must be installed\nUser will be prompted to enter \"YES\" to confirm job submission\nJob array size is controlled by SLURM_max_array_jobs_running\n\nExample\n\nusing GenomicBreeding, StatsBase;\nusing GenomicBreeding: cv, fit, predict, gwas, ols, rigde, lasso, bayesa, bayesb, bayesc, gwasols, gwaslmm, gwasreml;\ngenomes = GenomicBreeding.GBCore.simulategenomes(n=300, l=1_000, verbose=false); genomes.populations = StatsBase.sample(string.(\"pop_\", 1:3), length(genomes.entries), replace=true);\ntrials, _ = GenomicBreeding.GBCore.simulatetrials(genomes=genomes, n_years=1, n_seasons=1, n_harvests=1, n_sites=1, n_replications=1, verbose=false);\nphenomes = extractphenomes(trials);\nfname_geno = try writedelimited(genomes, fname=\"test-geno.tsv\"); catch; rm(\"test-geno.tsv\"); writedelimited(genomes, fname=\"test-geno.tsv\"); end;\nfname_pheno = try writedelimited(phenomes, fname=\"test-pheno.tsv\"); catch; rm(\"test-pheno.tsv\"); writedelimited(phenomes, fname=\"test-pheno.tsv\"); end;\n\n# Repeated k-fold cross-validation\ninput_cv = GBInput(fname_geno=fname_geno, fname_pheno=fname_pheno, analysis=cv, SLURM_account_name=\"dbiof1\", SLURM_cpus_per_task=5, SLURM_mem_G=5, fname_out_prefix=\"GBOutput/test-\", verbose=false);\noutdir = submitslurmarrayjobs(input_cv); ### You will be asked to enter \"YES\" to proceed with job submission.\nrun(`sh -c 'squeue -u \"$USER\"'`)\nrun(`sh -c 'tail slurm-*_*.out'`)\nrun(`sh -c 'grep -i \"err\" slurm-*_*.out'`)\ncvs = loadcvs(input_cv)\ndf_across_entries, df_per_entry = tabularise(cvs)\nsum(df_across_entries.model .== \"bayesa\") / nrow(df_across_entries)\nsum(df_across_entries.model .== \"ridge\") / nrow(df_across_entries)\nsort(combine(groupby(df_across_entries, [:validation_population, :model]), [:cor => mean, :cor => length]), :cor_mean, rev=true)\n\n# Genomic prediction equation full data fit\ninput_fit = clone(input_cv)\ninput_fit.analysis = fit\noutdir = submitslurmarrayjobs(input_fit);\ninput_fit.fname_allele_effects_jld2s = begin\n    files = readdir(outdir)\n    idx = findall(.!isnothing.(match.(Regex(\"-fit-\"), files)) .&& .!isnothing.(match.(Regex(\"jld2$\"), files)))\n    joinpath.(outdir, files[idx])\nend\nfits = loadfits(input_fit)\nlength(fits)\n\ninput_predict = clone(input_fit)\ninput_predict.analysis = predict\noutdir = submitslurmarrayjobs(input_predict)\nrun(`squeue`)\n\n\n\n\n\n","category":"method"},{"location":"manual/#Manual","page":"Manual","title":"Manual","text":"","category":"section"},{"location":"manual/","page":"Manual","title":"Manual","text":"Pages = [\"manual.md\"]\nDepth = 3","category":"page"},{"location":"manual/#Main","page":"Manual","title":"Main","text":"","category":"section"},{"location":"manual/","page":"Manual","title":"Manual","text":"GBInput: Struct for input data.\ncheckinputs: Check input data.\nloadgenomesphenomes: Load genomic and phenomic data.\nloadcvs: Load cross-validation data.\nloadfits: Load model fits.\nprepareinputs: Prepare input data.\nprepareoutprefixandoutdir: Prepare output prefix and directory.\ncv: Perform cross-validation.\nfit: Fit models.\npredict: Make predictions.\ngwas: Perform genome-wide association studies.\nsubmitslurmarrayjobs: Submit SLURM array jobs.\nplot: General plotting function.","category":"page"},{"location":"manual/#Core-Data-Structures","page":"Manual","title":"Core Data Structures","text":"","category":"section"},{"location":"manual/","page":"Manual","title":"Manual","text":"AbstractGB: Abstract type for genomic breeding data.\nGenomes: Struct for genomic data.\nPhenomes: Struct for phenomic data.\nTrials: Struct for trials data.\nSimulatedEffects: Struct for simulated genetic effects.\nTEBV: Struct for trial-estimated breeding values.\nFit: Struct for genotype-to-phenotype models.\nCV: Struct for cross-validation of genotype-to-phenotype models.","category":"page"},{"location":"manual/#General-Functions","page":"Manual","title":"General Functions","text":"","category":"section"},{"location":"manual/","page":"Manual","title":"Manual","text":"clone: Clone a struct.\nhash: Compute the hash of a struct.\n==: Check equality of structs.\ncheckdims: Check dimensions of genomic data.\ndimensions: Get dimensions of genomic data.\nloci_alleles: Get loci alleles.\nloci: Get loci.\nplot: Plot genomic data.\nslice: Slice genomic data.\nfilter: Filter genomic data.\ntabularise: Convert genomic data to a tabular format.\nsummarise: Summarise genomic data.","category":"page"},{"location":"manual/#Simulation-Functions","page":"Manual","title":"Simulation Functions","text":"","category":"section"},{"location":"manual/","page":"Manual","title":"Manual","text":"simulategenomes: Simulate genomic data.\nsimulateeffects: Simulate genetic effects.\nsimulategenomiceffects: Simulate genomic effects.\nsimulatetrials: Simulate trials data.","category":"page"},{"location":"manual/#Phenotype-Analysis-Functions","page":"Manual","title":"Phenotype Analysis Functions","text":"","category":"section"},{"location":"manual/","page":"Manual","title":"Manual","text":"countlevels: Count levels in phenomic data.\n@string2formula: Convert string to formula.\ntrialsmodelsfomulae!: Generate trial models formulae.\nanalyse: Analyse phenomic data.\nextractphenomes: Extract phenomic data.\n@stringevaluation: Evaluate string expressions.\naddcompositetrait: Add composite trait to phenomic data.","category":"page"},{"location":"manual/#Input/Output-Functions-(GBIO)","page":"Manual","title":"Input/Output Functions (GBIO)","text":"","category":"section"},{"location":"manual/","page":"Manual","title":"Manual","text":"levenshteindistance: Compute Levenshtein distance for fuzzy matching.\nisfuzzymatch: Check for fuzzy matches.\nreadjld2: Read JLD2 files.\nreaddelimited: Read delimited text files.\nreadvcf: Read VCF files.\nwritejld2: Write JLD2 files.\nwritedelimited: Write delimited text files.\nwritevcf: Write VCF files.","category":"page"},{"location":"manual/#Genomic-Prediction-Functions-(GBModels)","page":"Manual","title":"Genomic Prediction Functions (GBModels)","text":"","category":"section"},{"location":"manual/","page":"Manual","title":"Manual","text":"metrics: Compute metrics for model evaluation.\nextractxyetc: Extract features and targets for modeling.\npredict: Make predictions using trained models.\ngrmsimple: Compute genomic relationship matrix (simple).\ngrmploidyaware: Compute genomic relationship matrix (ploidy-aware).\ngwasprep: Prepare data for GWAS.\ngwasols: Perform GWAS using ordinary least squares.\ngwaslmm: Perform GWAS using linear mixed models.\nloglikreml: Compute log-likelihood for REML.\ngwasreml: Perform GWAS using REML.\nsquare, invoneplus, log10epsdivlog10eps, mult, addnorm, raise: Utility functions for transformations.\ntransform1, transform2, epistasisfeatures, @string2operations, reconstitutefeatures: Functions for feature engineering.\nbglr, bayesian: Bayesian genomic prediction models.\nturing_bayesG, turing_bayesGs, turing_bayesGπ, turing_bayesGπs, turing_bayesL, turing_bayesLs, turing_bayesLπ, turing_bayesLπs, turing_bayesT, turing_bayesTπ, turing_bayesG_logit: Turing Bayesian models.\nols, ridge, lasso, bayesa, bayesb, bayesc: Linear and Bayesian regression models.\nvalidate: Validate models.\ncvmultithread!, cvbulk: Cross-validation functions.\ncvperpopulation, cvpairwisepopulation, cvleaveonepopulationout: Cross-validation strategies.","category":"page"},{"location":"manual/#Plotting-Functions-(GBPlots)","page":"Manual","title":"Plotting Functions (GBPlots)","text":"","category":"section"},{"location":"manual/","page":"Manual","title":"Manual","text":"PlotsGB: General plotting functions.\nDistributionPlots: Distribution plots.\nViolinPlots: Violin plots.\nCorHeatPlots: Correlation heatmaps.\nTreePlots: Tree plots.\nBarPlots: Bar plots.\nBoxPlots: Box plots.\nPCBiPlots: Principal component biplots.\ncheckdims: Check dimensions for plotting.\nlabeltofname: Convert labels to filenames.\nsaveplots: Save plots to files.","category":"page"},{"location":"#GenomicBreeding.jl","page":"Home","title":"GenomicBreeding.jl","text":"","category":"section"},{"location":"#Contents","page":"Home","title":"Contents","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Pages = [\"index.md\"]\nDepth = 3","category":"page"},{"location":"#Overview","page":"Home","title":"Overview","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"The GenomicBreeding module provides a comprehensive suite of tools for genomic prediction, genome-wide association studies (GWAS), and data handling in genomic breeding. It integrates functionalities from GBCore, GBIO, GBModels, and GBPlots to offer efficient and scalable solutions for genetic data analysis and visualisation.","category":"page"},{"location":"#Installation","page":"Home","title":"Installation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"We designed GenomicBreeding.jl to work on an HPC running Linux (the various components, i.e. GBCore.jl, GBIO.jl, GBModels.jl, and GBPlots.jl work on a single Linux PC too).","category":"page"},{"location":"","page":"Home","title":"Home","text":"Currently, we require that you install Julia on your home directory in your HPC cluster via:","category":"page"},{"location":"","page":"Home","title":"Home","text":"curl -fsSL https://install.julialang.org | sh\ntype -a julia","category":"page"},{"location":"","page":"Home","title":"Home","text":"Currently, GBModels.jl is dependent on R and the package BGLR for Bayes A, Bayes B and Bayes C models. Because of this we require that R and BGLR be installed. To help with this, you may install all the requirements via Conda using the environment file: GenomicBreeding_conda.yml. We aim to have a pure Julia implementation of Bayesian models using Turing.jl in the near future (we just need to speed-up the models a bit).","category":"page"},{"location":"","page":"Home","title":"Home","text":"Install the GenomicBreeding.jl library in Julia:","category":"page"},{"location":"","page":"Home","title":"Home","text":"using Pkg\nPkg.add(\"https://github.com/GenomicBreeding/GenomicBreeding.jl\")","category":"page"},{"location":"","page":"Home","title":"Home","text":"Feel free to install the GenomicBreeding.jl components as well as various other useful libraries:","category":"page"},{"location":"","page":"Home","title":"Home","text":"using Pkg\nGB_components = [\n    \"https://github.com/GenomicBreeding/GBCore.jl\",\n    \"https://github.com/GenomicBreeding/GBIO.jl\",\n    \"https://github.com/GenomicBreeding/GBModels.jl\",\n    \"https://github.com/GenomicBreeding/GBPlots.jl\",\n]\nfor P in GB_components\n    Pkg.add(url=P)\nend\nPkg.add([\"StatsBase\", \"MixedModels\", \"MultivariateStats\", \"UnicodePlots\", \"ColorSchemes\", \"CairoMakie\"])","category":"page"},{"location":"#Quickstart","page":"Home","title":"Quickstart","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Genomic prediction\nGenome-wide association study\nGenotype data filtering and imputation\nPhenotype data analyses\nCluster analyses\nPlotting\nMating simulations","category":"page"},{"location":"#Genomic-prediction","page":"Home","title":"Genomic prediction","text":"","category":"section"},{"location":"#Example-1:-using-simulated-data","page":"Home","title":"Example 1: using simulated data","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Here's a simple example using simulated data to perform replicated k-fold cross validation:","category":"page"},{"location":"","page":"Home","title":"Home","text":"# It is always a good idea to keep all your packages updated\nusing Pkg; Pkg.update()\n# Load GenomicBreeding\nusing GenomicBreeding\n# Load plotting and GP model functions\nimport GenomicBreeding: plot, lasso, bayesa\n# Simulate genotype and phenotype data\ngenomes = simulategenomes(n=300, l=1_000, verbose=true)\ngenomes.populations[1:100] .= \"pop1\"; genomes.populations[101:200] .= \"pop2\"; genomes.populations[201:300] .= \"pop3\" # simulate multiple populations\ntrials, _ = simulatetrials(genomes=genomes, n_years=1, n_seasons=1, n_harvests=1, n_sites=1, n_replications=1, verbose=true);\nphenomes = extractphenomes(trials)\nfname_geno = writedelimited(genomes, fname=\"test-geno.tsv\")\nfname_pheno = writedelimited(phenomes, fname=\"test-pheno.tsv\")\n# Input struct documentation\n@doc GBInput\n# Setup the input struct\ninput = GBInput(\n    fname_geno=fname_geno, \n    fname_pheno=fname_pheno,\n    anaysis=cv, # set analysis to use the `cv` function for replicated k-fold cross-validation\n    models = [lasso, bayesa],\n    n_folds=2, \n    n_replications=2, \n    SLURM_job_name=\"testGB\",\n    SLURM_account_name=\"dbiopast1\",\n    SLURM_cpus_per_task=2, \n    SLURM_mem_G=5, \n    SLURM_time_limit_dd_hhmmss=\"00-00:15:00\",\n    SLURM_max_array_jobs_running=10,\n    verbose=true\n)\n# Preliminary look at the genotype and phenotype data\nplot(input=input, format=\"png\", plot_size=(700, 500))\n# Documentation of the main user interface function (take note of the currently available analyses)\n@doc submitslurmarrayjobs\n# Submit the Slurm array jobs\n# Note that here you will be prompted to enter YES to proceed.\noutdir = submitslurmarrayjobs(input)\n# Monitor the Slurm jobs\nrun(`sh -c 'squeue -u $USER'`)\nrun(`sh -c 'ls -lhtr slurm-*_*.out'`)\nrun(`sh -c 'cat slurm-*_*.out'`)\nrun(`sh -c 'tail slurm-*_*.out'`)\nrun(`sh -c 'grep -i \"err\" slurm-*_*.out'`)\nrun(`sh -c 'grep -i \"err\" slurm-*_*.out | cut -d: -f1 | sort | uniq'`)\nreaddir(outdir)\n# Once the array jobs have finishes or at least a couple of jobs have finished, run below.\n# Rerun as you often as wish to update the plots.\n# You may exit Julia and just run the plotting function below after correctly defining input::GBInput above.\nplot(input=input, format=\"png\", plot_size=(700, 500), skip_genomes=true, skip_phenomes=true, overwrite=true)","category":"page"},{"location":"#Example-2:-using-empirical-data","page":"Home","title":"Example 2: using empirical data","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"# TODO\n# with GP per se on unphenotyped set","category":"page"},{"location":"#Genome-wide-association-study","page":"Home","title":"Genome-wide association study","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"# TODO","category":"page"},{"location":"#Genotype-data-filtering-and-imputation","page":"Home","title":"Genotype data filtering and imputation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"# TODO","category":"page"},{"location":"#Phenotype-data-analyses","page":"Home","title":"Phenotype data analyses","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"# TODO","category":"page"},{"location":"#Cluster-analyses","page":"Home","title":"Cluster analyses","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"# TODO","category":"page"},{"location":"#Plotting","page":"Home","title":"Plotting","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"# TODO","category":"page"},{"location":"#Mating-simulations","page":"Home","title":"Mating simulations","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"# TODO","category":"page"},{"location":"#File-formats","page":"Home","title":"File formats","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Variant call format\nAllele frequency table\nJLD2\nTrials table\nPhenomes table ","category":"page"},{"location":"#Variant-call-format","page":"Home","title":"Variant call format","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"See VCFv4.2 and VCFv4.3 for details in the format specifications.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Note that given that we work with autopolyploids, and pools (e.g. half-sib families) more often, the VCF parser prioritise the AF (allele frequency) field, followed by the AD (allele depth) field, and finally the GT (genotype) field. If your VCF file needs depth-based filtering, you may opt for having the AD field instead of the AF field, as well as include the DP (depth) field. A way to generate a VCF file with AD and DP fields is via: ","category":"page"},{"location":"","page":"Home","title":"Home","text":"time \\\nbcftools mpileup \\\n    -BI \\\n    -a AD,DP \\\n    -d 4000000 \\\n    -f ${REF} \\\n    -T ${LOCI} \\\n    -b ${BAMS_LIST} \\\n    -Ov > ${PREFIX}-MPILEUP.vcf","category":"page"},{"location":"","page":"Home","title":"Home","text":"where the following flags refer to:","category":"page"},{"location":"","page":"Home","title":"Home","text":"-B: disable probabilistic realignment for the computation of base alignment quality (BAQ). BAQ is the Phred-scaled probability of a read base being misaligned. Applying this option greatly helps to reduce false SNPs caused by misalignments.\n-I: do not perform INDEL calling\n-a AD,DP: comma-separated list of FORMAT and INFO tags to output, i.e. Total allelic depth (Number=R,Type=Integer) (AD) and Number of high-quality bases (Number=1,Type=Integer) (DP)\n-Ou: output uncompressed BCF, because we're piping into bcftools call\n-d 4000000: at each position, read maximally 4 million reads per input file\n-f ...: reference genome in fasta format\n-T ...: regions or loci specified in a tab-delimited file. The columns of the tab-delimited file can contain either positions (two-column format: CHROM, POS) or intervals (three-column format: CHROM, BEG, END), but not both. Positions are 1-based and inclusive.\n-b ...: list of input alignment files, one file per line","category":"page"},{"location":"#Allele-frequency-table","page":"Home","title":"Allele frequency table","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"This is a simple human-readable string-delimited text file (tab-delimited by default). The smallest minimal valid allele frequency table is as follows:","category":"page"},{"location":"","page":"Home","title":"Home","text":"chrom pos all_alleles allele entry_1\nchr_1 123 A T A","category":"page"},{"location":"","page":"Home","title":"Home","text":"Each column must be sorted exactly as this: starting with \"chrom\" for chromosome or scaffold name, \"pos\" for the position in bases, \"all_alleles\" for a string of reference and alternative alleles separated by pipe/s (|), \"allele\" for exactly one of the alleles in the previous column, and finally subsequency column names refer to the names of the entries. Values under the 5th and subsequent columns are assumed to be allele frequencies, i.e. ranges from 0.0 to 1.0. Missing values may be encoded as any of the following:","category":"page"},{"location":"","page":"Home","title":"Home","text":"\"\"\n\"missing\"\n\"NA\"\n\"na\"\n\"N/A\"\n\"n/a\"","category":"page"},{"location":"","page":"Home","title":"Home","text":"An additional header may be included, for example:","category":"page"},{"location":"","page":"Home","title":"Home","text":"chrom pos all_alleles allele entry_1 entry_2 entry_3\nchrom pos all_alleles allele pop_ABC pop_DEF pop_XYZ\nchr_1 123 A|T A 0.51 0.25 0.25","category":"page"},{"location":"","page":"Home","title":"Home","text":"where the first header is the same as the detailed above, while the second header replaces the entry names with the corresponding population or group the entries belong to.","category":"page"},{"location":"#JLD2","page":"Home","title":"JLD2","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"This is a compressed binary format containing Julia structs (e.g. genomes, and phenomes struct). It is a subset of the scientific data format HDF5.","category":"page"},{"location":"#Trials-table","page":"Home","title":"Trials table","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Similar to the allele frequency table format, this is a simple human-readable string-delimited text file (tab-delimited by default). The smallest minimal valid trials table is as follows:","category":"page"},{"location":"","page":"Home","title":"Home","text":"years seasons harvests sites entries populations replications blocks rows cols trait_1\n2023 2023EarlySpring FLIGHT-2023-09-05 LOC1_TRT1 entry_1 pop_1 rep_1 row1 row1 col1 3.1416","category":"page"},{"location":"","page":"Home","title":"Home","text":"The first 10 columns must be named (or as close as possible) as the following in any order: ","category":"page"},{"location":"","page":"Home","title":"Home","text":"\"years\"\n\"seasons\"\n\"harvests\"\n\"sites\"\n\"entries\"\n\"populations\"\n\"replications\"\n\"blocks\"\n\"rows\"\n\"cols\"","category":"page"},{"location":"","page":"Home","title":"Home","text":"The subsequent columns (column 11 and so on) refer to the name of the traits. Values under the 11th and subsequent columns are assumed to be numeric. Missing values may be encoded as any of the following:","category":"page"},{"location":"","page":"Home","title":"Home","text":"\"\"\n\"missing\"\n\"NA\"\n\"na\"\n\"N/A\"\n\"n/a\"","category":"page"},{"location":"#Phenomes-table","page":"Home","title":"Phenomes table","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Again, similar to the allele frequency table format, this is a simple human-readable string-delimited text file (tab-delimited by default). The smallest minimal valid phenomes table is as follows:","category":"page"},{"location":"","page":"Home","title":"Home","text":"entries populations trait_1\nentry_1 pop_XYZ 0.5772","category":"page"},{"location":"","page":"Home","title":"Home","text":"Each column must be sorted exactly as this: starting with \"entries\" for the names of the entries, genotypes, families or pools, \"populations\" for the corresponding population names or group names. Subsequent column names (column 3 and so on) refer to the trait names. Values under the 3rd and subsequent columns are assumed to be numeric. Missing values may be encoded as any of the following:","category":"page"},{"location":"","page":"Home","title":"Home","text":"\"\"\n\"missing\"\n\"NA\"\n\"na\"\n\"N/A\"\n\"n/a\"","category":"page"},{"location":"#License","page":"Home","title":"License","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"The GenomicBreeding module is licensed under the GPLv3 License. See the LICENSE.md file for more details.","category":"page"},{"location":"#main-index","page":"Home","title":"Index","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Pages = [\"references.md\"]","category":"page"}]
}
